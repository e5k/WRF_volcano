{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"WRF-Volcano tutorial This page is written by Alex Poulidis (Bremen University) and S\u00e9bastien Biass (Universit\u00e9 de Gen\u00e8ve) and is designed to provide a hands-on approach to running WRF for applications in volcanology. Feel free to use any of the material for research or education purposes, but we would be grateful if you could contribute back with any new material. Getting started Cluster documentation Yggdrasil (Universit\u00e9 de Gen\u00e8ve) WRF documentation \ud83d\udcd6 WRF user guide Download ERA5 data Using MARS (\u2192 UNIGE users) ERA5 data should be placed in /srv/beegfs/scratch/shares/wrf_volcano/MET/ERA5/case_name Setup a run On the cluster Copy/clone script from /srv/beegfs/scratch/shares/wrf_volcano/ . Run ./setup_wrf.sh case_name , where case_name is your project/case name. This will: Create a folder named WRF_projects/case_name/ both on HOME and on scratch . The folder on the HOME partition contains the config files (i.e., namelist.* ) and are backed up. The folder on the scratch partition contains the WPS/ and WRF/ folders, which will store most of the data. Overview of the WRF workflow The process of running WRF consists of two steps: Pre-processing using the WRF Preprocessing System ( WPS ): WPS is a set of three programs whose collective role is to prepare input for real-data simulations Running WRF . flowchart TD classDef classA fill:#7e95af; classDef classB fill:#fc6f03; classDef classC fill:#a13ddb; T(Terrestrial):::classA subgraph WPS T --> geogrid--> metgrid M(MET):::classA --> ungrib --> ERA5-T:::classC --> metgrid namelist.wps:::classB -.-> geogrid namelist.wps:::classB -.-> metgrid namelist.wps:::classB -.-> ungrib namelist.wps:::classB -.-> calc_ecmwf_p calc_ecmwf_p --> PRES-T:::classC --> metgrid metgrid --> met_em_.dD:::classC end met_em_.dD:::classC --> real real --> wrfinput_dD:::classC --> WRF real --> wrfbdy_d01:::classC --> WRF namelist.input:::classB -.-> real namelist.input:::classB -.-> WRF --> wrfout_dD_T:::classC flowchart TD classDef classA fill:#7e95af; classDef classB fill:#fc6f03; classDef classC fill:#a13ddb; I(Input dataset):::classA O(Output file):::classC C(Configuration file):::classB P(Executable) Variables In the above flowchart and in the description below: T represents time is a string of format yyyy-mm-dd_hh D represents a domain numbered as 1 \u2192 n , where 1 is the outermost domain and n is the number of domains Setup WPS \ud83d\udcd6 WPS user guide cd case_name/WPS Edit the namelist.wps configuration file for WPS module load GCC/10.3.0 OpenMPI/4.1.1 WPS srun geogrid.exe Define the simulation domains, and to interpolate various terrestrial data sets to the model grids. \u2192 Outputs one NetCDF file per domain srun ungrib.exe Creates intermediary files (e.g., translate data from ERA, GFS or any other met model) \u2192 Creates one ERA5-T file per time step srun calc_ecmwf_p.exe Calculates pressure levels for specifically for ERA5 \u2192 Creates one PRES-T file per time step Info Not all reanalysis datasets have all the variables required for WRF and this step is specific to ERA5. srun metgrid.exe Interpolates the intermediate-format meteorological data that onto the simulation domains defined by geogrid \u2192 Creates one met_em_.dD... file per domain per time step Ouptut from metgrid is in WPS/output/ Using run_wps.sh All steps can be automatised by running sbatch run_wps.sh Case setup / WRF \ud83d\udcd6 User guide cd ../WRF Edit the namelist.input configuration file srun real.exe : Reads the met_em... files and creates input and boundary files, input files being the atmospheric state at \\(t=0\\) \u2192 wrfinput_dD boundary files are tendencies (\u00b1fluxes) at the border to represent future states \u2192 wrfbdy_d01 \u2192 only outer domain Info at \\(t=0\\) , everything is based on input data at \\(t>0\\) , input data only affect boundaries Job submission sbatch wrf Ouptut in case_name/WRF/output Using run_wrf.sh All steps can be automatised by running sbatch run_wrf.sh . Adapt the number of required CPU using ntasks and -n as needed. \u2757Too many processors can prevent the run to complete. How to check the status of a run? tail rsl.error.0000 \u2192 check computation time for each time step and estimate the remaining time Check files with ncview \u2192 check vertical velocity, where bad runs typically: Outputting only nan though the job did not crash Checkerboard pattern following grid points Large w values (\u00b160 ms-1)","title":"Home"},{"location":"#wrf-volcano-tutorial","text":"This page is written by Alex Poulidis (Bremen University) and S\u00e9bastien Biass (Universit\u00e9 de Gen\u00e8ve) and is designed to provide a hands-on approach to running WRF for applications in volcanology. Feel free to use any of the material for research or education purposes, but we would be grateful if you could contribute back with any new material.","title":"WRF-Volcano tutorial"},{"location":"#getting-started","text":"","title":"Getting started"},{"location":"#cluster-documentation","text":"Yggdrasil (Universit\u00e9 de Gen\u00e8ve)","title":"Cluster documentation"},{"location":"#wrf-documentation","text":"\ud83d\udcd6 WRF user guide","title":"WRF documentation"},{"location":"#download-era5-data","text":"Using MARS (\u2192 UNIGE users) ERA5 data should be placed in /srv/beegfs/scratch/shares/wrf_volcano/MET/ERA5/case_name","title":"Download ERA5 data"},{"location":"#setup-a-run","text":"On the cluster Copy/clone script from /srv/beegfs/scratch/shares/wrf_volcano/ . Run ./setup_wrf.sh case_name , where case_name is your project/case name. This will: Create a folder named WRF_projects/case_name/ both on HOME and on scratch . The folder on the HOME partition contains the config files (i.e., namelist.* ) and are backed up. The folder on the scratch partition contains the WPS/ and WRF/ folders, which will store most of the data.","title":"Setup a run"},{"location":"#overview-of-the-wrf-workflow","text":"The process of running WRF consists of two steps: Pre-processing using the WRF Preprocessing System ( WPS ): WPS is a set of three programs whose collective role is to prepare input for real-data simulations Running WRF . flowchart TD classDef classA fill:#7e95af; classDef classB fill:#fc6f03; classDef classC fill:#a13ddb; T(Terrestrial):::classA subgraph WPS T --> geogrid--> metgrid M(MET):::classA --> ungrib --> ERA5-T:::classC --> metgrid namelist.wps:::classB -.-> geogrid namelist.wps:::classB -.-> metgrid namelist.wps:::classB -.-> ungrib namelist.wps:::classB -.-> calc_ecmwf_p calc_ecmwf_p --> PRES-T:::classC --> metgrid metgrid --> met_em_.dD:::classC end met_em_.dD:::classC --> real real --> wrfinput_dD:::classC --> WRF real --> wrfbdy_d01:::classC --> WRF namelist.input:::classB -.-> real namelist.input:::classB -.-> WRF --> wrfout_dD_T:::classC flowchart TD classDef classA fill:#7e95af; classDef classB fill:#fc6f03; classDef classC fill:#a13ddb; I(Input dataset):::classA O(Output file):::classC C(Configuration file):::classB P(Executable) Variables In the above flowchart and in the description below: T represents time is a string of format yyyy-mm-dd_hh D represents a domain numbered as 1 \u2192 n , where 1 is the outermost domain and n is the number of domains","title":"Overview of the WRF workflow"},{"location":"#setup-wps","text":"\ud83d\udcd6 WPS user guide cd case_name/WPS Edit the namelist.wps configuration file for WPS module load GCC/10.3.0 OpenMPI/4.1.1 WPS srun geogrid.exe Define the simulation domains, and to interpolate various terrestrial data sets to the model grids. \u2192 Outputs one NetCDF file per domain srun ungrib.exe Creates intermediary files (e.g., translate data from ERA, GFS or any other met model) \u2192 Creates one ERA5-T file per time step srun calc_ecmwf_p.exe Calculates pressure levels for specifically for ERA5 \u2192 Creates one PRES-T file per time step Info Not all reanalysis datasets have all the variables required for WRF and this step is specific to ERA5. srun metgrid.exe Interpolates the intermediate-format meteorological data that onto the simulation domains defined by geogrid \u2192 Creates one met_em_.dD... file per domain per time step Ouptut from metgrid is in WPS/output/ Using run_wps.sh All steps can be automatised by running sbatch run_wps.sh","title":"Setup WPS"},{"location":"#case-setup-wrf","text":"\ud83d\udcd6 User guide cd ../WRF Edit the namelist.input configuration file srun real.exe : Reads the met_em... files and creates input and boundary files, input files being the atmospheric state at \\(t=0\\) \u2192 wrfinput_dD boundary files are tendencies (\u00b1fluxes) at the border to represent future states \u2192 wrfbdy_d01 \u2192 only outer domain Info at \\(t=0\\) , everything is based on input data at \\(t>0\\) , input data only affect boundaries Job submission sbatch wrf Ouptut in case_name/WRF/output Using run_wrf.sh All steps can be automatised by running sbatch run_wrf.sh . Adapt the number of required CPU using ntasks and -n as needed. \u2757Too many processors can prevent the run to complete. How to check the status of a run? tail rsl.error.0000 \u2192 check computation time for each time step and estimate the remaining time Check files with ncview \u2192 check vertical velocity, where bad runs typically: Outputting only nan though the job did not crash Checkerboard pattern following grid points Large w values (\u00b160 ms-1)","title":"Case setup / WRF"},{"location":"changelog/","text":"Changelog 2022-07-24 The website was moved from an organisation (CERG-C.github.io) to a project (CERG-C) Github page. Now CERG-C.github.io contains only an index.html page with an automatic redirection.","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#2022-07-24","text":"The website was moved from an organisation (CERG-C.github.io) to a project (CERG-C) Github page. Now CERG-C.github.io contains only an index.html page with an automatic redirection.","title":"2022-07-24"},{"location":"contribute/","text":"Contribute to the teaching material This website is stored as a project site Github page and is stored on the CERG-C github repository. The documentation is written in Markdown , and built into a website using the static website generator MkDocs with the Material for MkDocs theme. Building and deploying the website requires some knowledge of Python and Git . Installing the website It is recommended to setup the website in a Conda environment rather than on the system's Python distribution. Setting up an environment Installing dependencies Contributing to the course Markdown native Library-specific Citations/references: As footnotes Abbreviations: Deploying the website We use mike to keep track of versions . The active version is always set with the latest label, so make sure it is set by default. From the root of the CERG-C repository, run from the terminal: mike set-default latest When working on a new version, push the website using a dummy label - here test . mike deploy --push --update-aliases 2022.1 test When happy with your changes, use the latest label. mike deploy --push --update-aliases 2022.1 latest Different versions are accessible with their version numbers. For instance, the url of version 2022.1 is https://cerg-c.github.io/CERG-C/2022.1/. Keep track of versions! Log the purpose of the versions here ]! Old website version The website was initially stored as an organisation site Github page in the repo CERG-C.github.io , for which deployment was done with: mkdocs gh-deploy --force --remote-branch main --config-file mkdocs.yml","title":"Contribute to the teaching material"},{"location":"contribute/#contribute-to-the-teaching-material","text":"This website is stored as a project site Github page and is stored on the CERG-C github repository. The documentation is written in Markdown , and built into a website using the static website generator MkDocs with the Material for MkDocs theme. Building and deploying the website requires some knowledge of Python and Git .","title":"Contribute to the teaching material"},{"location":"contribute/#installing-the-website","text":"It is recommended to setup the website in a Conda environment rather than on the system's Python distribution.","title":"Installing the website"},{"location":"contribute/#setting-up-an-environment","text":"","title":"Setting up an environment"},{"location":"contribute/#installing-dependencies","text":"","title":"Installing dependencies"},{"location":"contribute/#contributing-to-the-course","text":"","title":"Contributing to the course"},{"location":"contribute/#markdown-native","text":"","title":"Markdown native"},{"location":"contribute/#library-specific","text":"Citations/references: As footnotes Abbreviations:","title":"Library-specific"},{"location":"contribute/#deploying-the-website","text":"We use mike to keep track of versions . The active version is always set with the latest label, so make sure it is set by default. From the root of the CERG-C repository, run from the terminal: mike set-default latest When working on a new version, push the website using a dummy label - here test . mike deploy --push --update-aliases 2022.1 test When happy with your changes, use the latest label. mike deploy --push --update-aliases 2022.1 latest Different versions are accessible with their version numbers. For instance, the url of version 2022.1 is https://cerg-c.github.io/CERG-C/2022.1/. Keep track of versions! Log the purpose of the versions here ]!","title":"Deploying the website"},{"location":"contribute/#old-website-version","text":"The website was initially stored as an organisation site Github page in the repo CERG-C.github.io , for which deployment was done with: mkdocs gh-deploy --force --remote-branch main --config-file mkdocs.yml","title":"Old website version"},{"location":"howto/","text":"How-to's Random advices on some of the steps. Setup run duration The first 12h of any WRF run is spinup . This is the time required for the model to become quasi-steady state, so any run should at least be 12h. Setup domains General rules Setting up nested domains should be an iterative process. Make sure the parent domain is properly located before creating a child domain Domains should as much as possible having mountains on domains boundaries. The smaller the grid spacing, the more important mountains become (i.e., at the resolution of ERA5, topography is essentially flat) The outermost domain is the computationally cheapest one. The best practice is to set a large outer domain rather than push the child domains too close to the parent's boundaries The outermost domain controls the decomposition of the grid for run parallelisation. A small outer domain will prevent using a large number of CPU Setting up the outer domain Setup an outer domain , which should: Be centered on the point of interest Should have at least 100x100 points of the original data. The grid spacing of the outer domain should be \u2265 than 1/3rd of the grid spacing of the meteorological data. If nudging is used, the grid spacing of the outer domain must be the same than the original data. Setting up child domains Each child domain should be at most ~1/3rd of the parent domain in both size and grid spacing to avoid boundary effects","title":"How to"},{"location":"howto/#how-tos","text":"Random advices on some of the steps.","title":"How-to's"},{"location":"howto/#setup-run-duration","text":"The first 12h of any WRF run is spinup . This is the time required for the model to become quasi-steady state, so any run should at least be 12h.","title":"Setup run duration"},{"location":"howto/#setup-domains","text":"","title":"Setup domains"},{"location":"howto/#general-rules","text":"Setting up nested domains should be an iterative process. Make sure the parent domain is properly located before creating a child domain Domains should as much as possible having mountains on domains boundaries. The smaller the grid spacing, the more important mountains become (i.e., at the resolution of ERA5, topography is essentially flat) The outermost domain is the computationally cheapest one. The best practice is to set a large outer domain rather than push the child domains too close to the parent's boundaries The outermost domain controls the decomposition of the grid for run parallelisation. A small outer domain will prevent using a large number of CPU","title":"General rules"},{"location":"howto/#setting-up-the-outer-domain","text":"Setup an outer domain , which should: Be centered on the point of interest Should have at least 100x100 points of the original data. The grid spacing of the outer domain should be \u2265 than 1/3rd of the grid spacing of the meteorological data. If nudging is used, the grid spacing of the outer domain must be the same than the original data.","title":"Setting up the outer domain"},{"location":"howto/#setting-up-child-domains","text":"Each child domain should be at most ~1/3rd of the parent domain in both size and grid spacing to avoid boundary effects","title":"Setting up child domains"},{"location":"versions/","text":"Versions v2022.cerg 2022 CERG-C teaching","title":"Versions"},{"location":"versions/#versions","text":"","title":"Versions"},{"location":"versions/#v2022cerg","text":"2022 CERG-C teaching","title":"v2022.cerg"}]}